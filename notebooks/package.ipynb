{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4a2eb9-4305-477a-b73d-e6e86fc7cb4a",
   "metadata": {},
   "source": [
    "# Examples of using the draft package 'propensity_reweighting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1beebd-424b-451d-af8d-119f2657c705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from propensity_reweighting.src.reweight import PropensityReweighter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import yaml\n",
    "\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "np.random.seed(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8395fd0d-2bed-4e44-b6eb-5df219384d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./propensity_reweighting/config/config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# texts = pd.read_csv('/workspace/local/edl/llm_propensity/qa_data_gpt_llama.csv')\n",
    "texts = pd.read_csv('./llm_propensity/QA_version_0506 - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8149d583-6616-45be-9fd2-3de13c656a15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Base 'fit' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954bfcfe-d343-4b63-9c5b-a05802d7771e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original = texts[texts[\"Time\"] == 'original'][\"Question\"].tolist()\n",
    "target = texts[texts[\"Time\"] == 'future'][\"Question\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab4d4a96-da4d-4584-b1ba-142d19fcccef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.2353\n",
      "Mean EMD on non-weighted test data: 0.0662\n",
      "Mean ED on non-weighted test data: 0.1332\n",
      "\n",
      "Mean k2 on weighted test data: 0.1955\n",
      "Mean EMD on weighted test data: 0.0537\n",
      "Mean ED on weighted test data: 0.1077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from propensity_reweighting.src.reweight import PropensityReweighter\n",
    "\n",
    "pr = PropensityReweighter(config)\n",
    "_ = pr.fit(original, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2264f2-d4f5-4f96-9fe2-1da04f23cf79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.82027115, 1.57874549, 1.82027115, 1.89444131, 1.45053357,\n",
       "       1.4528157 , 1.66747493, 1.57904128, 1.6913386 , 1.62518438])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = pr.predict(target)\n",
    "weights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f7453f-da65-4854-90c5-a745e2f3eacc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'predicted weights')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGzCAYAAAD0T7cVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjD0lEQVR4nO3dfVCVdf7/8dcBAtQAM0RBMfJ20wpXXMiMzMIhdHSyHG1rFc2bcYRNY7aG1jZ0utFqc1zrWGullplpVm6TN5l3qWWJoO0mapo3ebPiTSmIpsH5/P7w53FPInffwzkf4PmYYcZzcZ1zvc8HR55e5zrgMMYYAQAAWCLA3wMAAAD8L+IEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBGhg1q1bJ4fDoXXr1rm3DR8+XHFxcX6b6bfKm9EfJk2aJIfD8X+674kTJ7w8FVD/EScAauz555/XkiVL/D1Gncc6Ap6IEwB64403tGvXrmrfr75/U33qqad07ty5Wj9OfV9HoLqC/D0AgKpxuVy6cOGCQkNDvf7Y11xzjdcfsz4ICgpSUBD/TAK+xpkTwIcuXYewc+dODR48WOHh4br++us1fvx4/fLLLx77OhwOZWZmav78+erSpYtCQkK0YsUKSdLhw4f1yCOPqEWLFgoJCVGXLl00e/bsK4536NAh3XfffWrSpImioqL02GOP6fz581fsV941Jy6XS//4xz90yy23KDQ0VM2bN9e9996rLVu2uOcrKSnR22+/LYfDIYfDoeHDh7vv7+0Zf+vf//63HA6HPvnkE/e2vLw8ORwOdevWzWPftLQ0JSUleWxbvny5kpOT1aRJE4WFhalfv37avn27xz7lXXNy7tw5Pfroo4qMjFRYWJgGDBigw4cPy+FwaNKkSVfMeerUKQ0fPlxNmzZVRESERowYobNnz7o/X9E6FhcXa8KECYqLi1NISIiioqLUp08f5efnV7o+QF3GfwkAPxg8eLDi4uI0ZcoUff3115oxY4Z+/vlnvfPOOx77rVmzRosWLVJmZqYiIyMVFxenwsJC3Xbbbe54ad68uZYvX66RI0eqqKhIEyZMkHTxm+g999yjH3/8UY8++qhiYmI0b948rVmzpkozjhw5UnPnzlVaWppGjRql0tJSbdiwQV9//bW6d++uefPmadSoUUpMTNSYMWMkSe3atZMkn8x48803q2nTplq/fr0GDBggSdqwYYMCAgL07bffqqioSOHh4XK5XPrqq6/cM0rSvHnzlJ6ertTUVL3wwgs6e/asXnvtNd1xxx3aunVrhRcHDx8+XIsWLdLQoUN122236YsvvlC/fv2uuv/gwYN14403asqUKcrPz9ebb76pqKgovfDCC+5ZrraOY8eO1eLFi5WZmanOnTvr5MmT2rhxo3bs2HFFgAH1igHgMzk5OUaSGTBggMf2cePGGUnm22+/dW+TZAICAsz27ds99h05cqSJjo42J06c8Nj+4IMPmoiICHP27FljjDHTp083ksyiRYvc+5SUlJj27dsbSWbt2rXu7enp6eaGG25w316zZo2RZB599NErnoPL5XL/uUmTJiY9Pf2KfWpjxvL069fPJCYmum/ff//95v777zeBgYFm+fLlxhhj8vPzjSTzr3/9yxhjTHFxsWnatKkZPXq0x2MdPXrUREREeGy/9PW6JC8vz0gyEyZM8Ljv8OHDjSSTk5NzxX0feeQRj30HDhxorr/+eo9tV1vHiIgIk5GRUeEaAPURL+sAfpCRkeFx+89//rMkadmyZR7be/Xqpc6dO7tvG2P04Ycfqn///jLG6MSJE+6P1NRUnT592n3Kf9myZYqOjtagQYPc92/cuLHHGYSr+fDDD+VwOJSTk3PF5yp7a62vZpSk5ORk5efnq6SkRJK0ceNG9e3bV127dtWGDRskXTyb4nA4dMcdd0iSPv/8c506dUp//OMfPWYLDAxUUlKS1q5de9XjXXpZbdy4cR7bL339yjN27NgrZj558qSKiooqfX5NmzbVN998oyNHjlS6L1Cf8LIO4AcdOnTwuN2uXTsFBARo//79HttvvPFGj9vHjx/XqVOnNGvWLM2aNavcxz527Jgk6cCBA2rfvv0VMdGpU6dK5/vhhx8UExOjZs2aVbrvb/lqRuniN/rS0lJt2rRJsbGxOnbsmJKTk7V9+3aPOOncubP7uezevVuSdPfdd5f7mOHh4Vc93oEDBxQQEHDF16V9+/ZXvU+bNm08bl933XWSpJ9//rnCY0nSiy++qPT0dMXGxiohIUF9+/bVsGHD1LZt2wrvB9R1xAlggaudjWjUqJHHbZfLJUn605/+pPT09HLvc+utt3p3uGry5Yzdu3dXaGio1q9frzZt2igqKkodO3ZUcnKyZs6cqfPnz2vDhg0aOHDgFfPNmzdPLVu2vOIxvf3unMDAwHK3G2Mqve/gwYOVnJysjz/+WCtXrtRLL72kF154QR999JHS0tK8OidgE+IE8IPdu3d7/O97z549crlclf6U1ubNmyssLExlZWVKSUmpcN8bbrhB3333nYwxHvFTlZ9n0q5dO3322Wf66aefKjx7Ul5U+WpGSQoODlZiYqI2bNigNm3aKDk5WdLFMyrnz5/X/PnzVVhYqDvvvNPjuUlSVFRUpfOVN6/L5dK+ffs8zn7t2bOnWo/zWxW9VBYdHa1x48Zp3LhxOnbsmLp166bnnnuOOEG9xjUngB84nU6P26+88ookVfoNJzAwUA888IA+/PBDfffdd1d8/vjx4+4/9+3bV0eOHNHixYvd286ePXvVl1r+1wMPPCBjjCZPnnzF5/73f/xNmjTRqVOn/DLjJcnJyfrmm2+0du1ad5xERkbqpptucr8j5tJ2SUpNTVV4eLief/55/frrrxXO91upqamSpJkzZ3psv/T1q6ny1rGsrEynT5/22BYVFaWYmJgqvdUaqMs4cwL4wb59+zRgwADde++92rRpk95991099NBDio+Pr/S+U6dO1dq1a5WUlKTRo0erc+fO+umnn5Sfn69Vq1bpp59+kiSNHj1ar776qoYNG6a8vDxFR0dr3rx5aty4caXH6N27t4YOHaoZM2Zo9+7duvfee+VyubRhwwb17t1bmZmZkqSEhAStWrVK06ZNU0xMjG688UYlJSX5ZMZLkpOT9dxzz+ngwYMeEXLnnXfqn//8p+Li4tS6dWv39vDwcL322msaOnSounXrpgcffFDNmzfXjz/+qKVLl6pnz5569dVXyz1WQkKCHnjgAU2fPl0nT550v5X4+++/l1T5xcJXU946durUSa1bt9agQYMUHx+va6+9VqtWrVJubq5efvnlGh0HqDP89j4hoAG69PbSgoICM2jQIBMWFmauu+46k5mZac6dO+exr6Srvo20sLDQZGRkmNjYWHPNNdeYli1bmnvuucfMmjXLY78DBw6YAQMGmMaNG5vIyEgzfvx4s2LFikrfSmyMMaWlpeall14yv/vd70xwcLBp3ry5SUtLM3l5ee59du7cae68807TqFEjI8nj7bDenvFqioqKTGBgoAkLCzOlpaXu7e+++66RZIYOHVru/dauXWtSU1NNRESECQ0NNe3atTPDhw83W7Zsce/z27cSG3Pxrc4ZGRmmWbNm5tprrzX33Xef2bVrl5Fkpk6desV9jx8/7nH/OXPmGElm3759Fa7j+fPnzeOPP27i4+NNWFiYadKkiYmPjzczZ86sdE2Aus5hTBWuygLgFZMmTdLkyZN1/PhxRUZG+nsceMm2bdv0+9//Xu+++64efvhhf48D1HlccwIA1VDeLwKcPn26AgICPC68BVBzXHMCANXw4osvKi8vT71791ZQUJCWL1+u5cuXa8yYMYqNjfX3eEC9QJwAQDXcfvvt+vzzz/XMM8/ozJkzatOmjSZNmqSJEyf6ezSg3uCaEwAAYBWuOQEAAFYhTgAAgFXq3DUnLpdLR44cUVhYWI1/4BEAAPAtY4yKi4sVExOjgICKz43UuTg5cuQIV8QDAFBHHTx40OOnNpenzsVJWFiYpItPrrJfNw4AAOxQVFSk2NhY9/fxitS5OLn0Uk54eDhxAgBAHVOVSzK4IBYAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFb/EycCBA3Xddddp0KBB/jg8AACwmF/iZPz48XrnnXf8cWgAAGA5v8TJXXfdVaWfrQ8AABqeasfJ+vXr1b9/f8XExMjhcGjJkiVX7ON0OhUXF6fQ0FAlJSVp8+bN3pgVAAA0ANWOk5KSEsXHx8vpdJb7+YULFyorK0s5OTnKz89XfHy8UlNTdezYsRoNeP78eRUVFXl8AACA+qvav5U4LS1NaWlpV/38tGnTNHr0aI0YMUKS9Prrr2vp0qWaPXu2srOzqz3glClTNHny5GrfDwCA+iIue2ml++yf2s8Hk/iGV685uXDhgvLy8pSSknL5AAEBSklJ0aZNm2r0mE8++aROnz7t/jh48KC3xgUAABaq9pmTipw4cUJlZWVq0aKFx/YWLVpo586d7tspKSn69ttvVVJSotatW+uDDz5Qjx49yn3MkJAQhYSEeHNMAABgMa/GSVWtWrXKH4cFAAB1gFdf1omMjFRgYKAKCws9thcWFqply5bePBQAAKinvBonwcHBSkhI0OrVq93bXC6XVq9efdWXbQAAAP5XtV/WOXPmjPbs2eO+vW/fPm3btk3NmjVTmzZtlJWVpfT0dHXv3l2JiYmaPn26SkpK3O/eAQAAqEi142TLli3q3bu3+3ZWVpYkKT09XXPnztWQIUN0/PhxPf300zp69Ki6du2qFStWXHGRLAAAQHkcxhjj7yGqo6ioSBERETp9+rTCw8P9PQ4AALWuPvyck+p8//bL79YBAAC4GuIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFbxyy/+qwmn0ymn06mysjJ/jwIA+P9s+/kbts2DmqkzZ04yMjJUUFCg3Nxcf48CAABqUZ2JEwAA0DAQJwAAwCrECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsEqQvweoKqfTKafTqbKyMn+PAgDwsrjspf4eoUGoyjrvn9rPB5NUrM6cOcnIyFBBQYFyc3P9PQoAAKhFdSZOAABAw0CcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACr1Jk4cTqd6ty5s/7whz/4exQAAFCL6kycZGRkqKCgQLm5uf4eBQAA1KI6EycAAKBhIE4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWCXI3wNUldPplNPpVFlZmb9HAQBAcdlLvfI4+6f288rjeGseG9SZMycZGRkqKChQbm6uv0cBAAC1qM7ECQAAaBiIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWC/D1AVTmdTjmdTpWVlfl7FACoFXHZSyvdZ//Ufj6YpH5jne1XZ86cZGRkqKCgQLm5uf4eBQAA1KI6EycAAKBhIE4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWC/D1AVTmdTjmdTpWVlfl7FAA1FJe9tNJ99k/t54NJLrJtHm/x1vOqyuNUhbcex5d8OXNdXJ/aVmfOnGRkZKigoEC5ubn+HgUAANSiOhMnAACgYSBOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYJcjfA1SV0+mU0+lUWVmZv0dRXPbSSvfZP7Wfzx6nIWvIa2jbc6/KPHXxWFXhy6+Fbc8dqA115sxJRkaGCgoKlJub6+9RAABALaozcQIAABoG4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABglSB/D1BVTqdTTqdTZWVl/h4FXhCXvbTSffZP7eezY1WFt+apCm/NjP87vhaA79WZMycZGRkqKChQbm6uv0cBAAC1qM7ECQAAaBiIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAVv8TJp59+qk6dOqlDhw568803/TECAACwVJCvD1haWqqsrCytXbtWERERSkhI0MCBA3X99df7ehQAAGAhn5852bx5s7p06aJWrVrp2muvVVpamlauXOnrMQAAgKWqHSfr169X//79FRMTI4fDoSVLllyxj9PpVFxcnEJDQ5WUlKTNmze7P3fkyBG1atXKfbtVq1Y6fPhwzaYHAAD1TrXjpKSkRPHx8XI6neV+fuHChcrKylJOTo7y8/MVHx+v1NRUHTt2rEYDnj9/XkVFRR4fAACg/qr2NSdpaWlKS0u76uenTZum0aNHa8SIEZKk119/XUuXLtXs2bOVnZ2tmJgYjzMlhw8fVmJi4lUfb8qUKZo8eXJ1x6yxuOylVj2OL1Vl5v1T+/lgkotYQ9+wbea6+HWvivr6vIDa4NVrTi5cuKC8vDylpKRcPkBAgFJSUrRp0yZJUmJior777jsdPnxYZ86c0fLly5WamnrVx3zyySd1+vRp98fBgwe9OTIAALCMV9+tc+LECZWVlalFixYe21u0aKGdO3dePGBQkF5++WX17t1bLpdLTzzxRIXv1AkJCVFISIg3xwQAABbz+VuJJWnAgAEaMGCAPw4NAAAs59WXdSIjIxUYGKjCwkKP7YWFhWrZsqU3DwUAAOopr8ZJcHCwEhIStHr1avc2l8ul1atXq0ePHt48FAAAqKeq/bLOmTNntGfPHvftffv2adu2bWrWrJnatGmjrKwspaenq3v37kpMTNT06dNVUlLifvcOAABARaodJ1u2bFHv3r3dt7OysiRJ6enpmjt3roYMGaLjx4/r6aef1tGjR9W1a1etWLHiiotkAQAAylPtOLnrrrtkjKlwn8zMTGVmZtZ4KAAA0HD55bcSAwAAXA1xAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACr+OUX/9WE0+mU0+lUaWmpJKmoqKhWjuM6f7ZWHremaut5lqcqz91b89i2zlVRlefurTX01vrUxZnhG3xNcTW19X3n0uNW9rPSJMlhqrKXRQ4dOqTY2Fh/jwEAAGrg4MGDat26dYX71Lk4cblcOnLkiMLCwuRwOPw2R1FRkWJjY3Xw4EGFh4f7bQ4bsBaXsRYXsQ6XsRaXsRaXNcS1MMaouLhYMTExCgio+KqSOvOyziUBAQGVFpcvhYeHN5i/WJVhLS5jLS5iHS5jLS5jLS5raGsRERFRpf24IBYAAFiFOAEAAFYhTmooJCREOTk5CgkJ8fcofsdaXMZaXMQ6XMZaXMZaXMZaVKzOXRALAADqN86cAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcVcDqdiouLU2hoqJKSkrR58+YK9z916pQyMjIUHR2tkJAQdezYUcuWLfPRtLWrumsxffp0derUSY0aNVJsbKwee+wx/fLLLz6atnasX79e/fv3V0xMjBwOh5YsWVLpfdatW6du3bopJCRE7du319y5c2t9Tl+o7lp89NFH6tOnj5o3b67w8HD16NFDn332mW+GrWU1+XtxyZdffqmgoCB17dq11ubzlZqsw/nz5zVx4kTdcMMNCgkJUVxcnGbPnl37w9aymqzF/PnzFR8fr8aNGys6OlqPPPKITp48WfvDWoo4uYqFCxcqKytLOTk5ys/PV3x8vFJTU3Xs2LFy979w4YL69Omj/fv3a/Hixdq1a5feeOMNtWrVyseTe1911+K9995Tdna2cnJytGPHDr311ltauHCh/vrXv/p4cu8qKSlRfHy8nE5nlfbft2+f+vXrp969e2vbtm2aMGGCRo0aVS++KVd3LdavX68+ffpo2bJlysvLU+/evdW/f39t3bq1lietfdVdi0tOnTqlYcOG6Z577qmlyXyrJuswePBgrV69Wm+99ZZ27dqlBQsWqFOnTrU4pW9Udy2+/PJLDRs2TCNHjtT27dv1wQcfaPPmzRo9enQtT2oxg3IlJiaajIwM9+2ysjITExNjpkyZUu7+r732mmnbtq25cOGCr0b0mequRUZGhrn77rs9tmVlZZmePXvW6py+JMl8/PHHFe7zxBNPmC5dunhsGzJkiElNTa3FyXyvKmtRns6dO5vJkyd7fyA/qs5aDBkyxDz11FMmJyfHxMfH1+pcvlaVdVi+fLmJiIgwJ0+e9M1QflKVtXjppZdM27ZtPbbNmDHDtGrVqhYnsxtnTspx4cIF5eXlKSUlxb0tICBAKSkp2rRpU7n3+eSTT9SjRw9lZGSoRYsWuvnmm/X888+rrKzMV2PXipqsxe233668vDz3Sz979+7VsmXL1LdvX5/MbItNmzZ5rJskpaamXnXdGhKXy6Xi4mI1a9bM36P4xZw5c7R3717l5OT4exS/+eSTT9S9e3e9+OKLatWqlTp27Ki//OUvOnfunL9H87kePXro4MGDWrZsmYwxKiws1OLFixvcv5n/q879VmJfOHHihMrKytSiRQuP7S1atNDOnTvLvc/evXu1Zs0aPfzww1q2bJn27NmjcePG6ddff63T/wDVZC0eeughnThxQnfccYeMMSotLdXYsWPr/Ms61XX06NFy162oqEjnzp1To0aN/DSZ//3973/XmTNnNHjwYH+P4nO7d+9Wdna2NmzYoKCghvtP8N69e7Vx40aFhobq448/1okTJzRu3DidPHlSc+bM8fd4PtWzZ0/Nnz9fQ4YM0S+//KLS0lL179+/2i8V1iecOfESl8ulqKgozZo1SwkJCRoyZIgmTpyo119/3d+j+dy6dev0/PPPa+bMmcrPz9dHH32kpUuX6plnnvH3aLDAe++9p8mTJ2vRokWKiory9zg+VVZWpoceekiTJ09Wx44d/T2OX7lcLjkcDs2fP1+JiYnq27evpk2bprfffrvBnT0pKCjQ+PHj9fTTTysvL08rVqzQ/v37NXbsWH+P5jcNN9srEBkZqcDAQBUWFnpsLywsVMuWLcu9T3R0tK655hoFBga6t9100006evSoLly4oODg4FqdubbUZC3+9re/aejQoRo1apQk6ZZbblFJSYnGjBmjiRMnKiCgYTRxy5Yty1238PDwBnvW5P3339eoUaP0wQcfXPGSV0NQXFysLVu2aOvWrcrMzJR08Zu0MUZBQUFauXKl7r77bj9P6RvR0dFq1aqVIiIi3NtuuukmGWN06NAhdejQwY/T+daUKVPUs2dPPf7445KkW2+9VU2aNFFycrKeffZZRUdH+3lC32sY3yWqKTg4WAkJCVq9erV7m8vl0urVq9WjR49y79OzZ0/t2bNHLpfLve37779XdHR0nQ0TqWZrcfbs2SsC5FK0mQb0eyZ79OjhsW6S9Pnnn1913eq7BQsWaMSIEVqwYIH69evn73H8Ijw8XP/5z3+0bds298fYsWPVqVMnbdu2TUlJSf4e0Wd69uypI0eO6MyZM+5t33//vQICAtS6dWs/TuZ7/JtZDn9ejWuz999/34SEhJi5c+eagoICM2bMGNO0aVNz9OhRY4wxQ4cONdnZ2e79f/zxRxMWFmYyMzPNrl27zKeffmqioqLMs88+66+n4DXVXYucnBwTFhZmFixYYPbu3WtWrlxp2rVrZwYPHuyvp+AVxcXFZuvWrWbr1q1Gkpk2bZrZunWrOXDggDHGmOzsbDN06FD3/nv37jWNGzc2jz/+uNmxY4dxOp0mMDDQrFixwl9PwWuquxbz5883QUFBxul0mv/+97/uj1OnTvnrKXhNddfit+rLu3Wquw7FxcWmdevWZtCgQWb79u3miy++MB06dDCjRo3y11PwmuquxZw5c0xQUJCZOXOm+eGHH8zGjRtN9+7dTWJior+egt8RJxV45ZVXTJs2bUxwcLBJTEw0X3/9tftzvXr1Munp6R77f/XVVyYpKcmEhISYtm3bmueee86Ulpb6eOraUZ21+PXXX82kSZNMu3btTGhoqImNjTXjxo0zP//8s+8H96K1a9caSVd8XHru6enpplevXlfcp2vXriY4ONi0bdvWzJkzx+dz14bqrkWvXr0q3L8uq8nfi/9VX+KkJuuwY8cOk5KSYho1amRat25tsrKyzNmzZ30/vJfVZC1mzJhhOnfubBo1amSio6PNww8/bA4dOuT74S3hMKahnjMCAAA24poTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAVvl/T1mO4Oe2TdAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(weights, bins=50)\n",
    "plt.yscale('log')\n",
    "plt.title('predicted weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d926bd-26e4-4e16-82b3-539b4b4d3408",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 'fit' with custom GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89c9429-4d37-432d-aeb9-c5cbb0abbd72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original = texts[texts[\"Time\"] == 'original'][\"Question\"].tolist()\n",
    "target = texts[texts[\"Time\"] == 'future'][\"Question\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae286094-047c-48c7-9f9b-caab86010f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab9220b493c495291662373286f1686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "({'n_estimators': 100, 'learning_rate': 0.009, 'max_depth': 5, 'min_samples_leaf': 1}, 0.027573379091440448)\n",
      "({'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 10, 'min_samples_leaf': 10}, 0.026775148148576972)\n",
      "({'n_estimators': 100, 'learning_rate': 0.009, 'max_depth': 5, 'min_samples_leaf': 10}, 0.026429746813873334)\n",
      "({'n_estimators': 100, 'learning_rate': 0.009, 'max_depth': 10, 'min_samples_leaf': 10}, 0.026383393071299232)\n",
      "({'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 10, 'min_samples_leaf': 1}, 0.025435030131440977)\n",
      "Best Parameters: {'n_estimators': 100, 'learning_rate': 0.009, 'max_depth': 5, 'min_samples_leaf': 1}\n",
      "Error: 0.027573379091440448\n",
      "\n",
      "Mean k2 on non-weighted test data: 0.2353\n",
      "Mean EMD on non-weighted test data: 0.0662\n",
      "Mean ED on non-weighted test data: 0.1332\n",
      "\n",
      "Mean k2 on weighted test data: 0.1591\n",
      "Mean EMD on weighted test data: 0.0386\n",
      "Mean ED on weighted test data: 0.0765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from propensity_reweighting.src.reweight import PropensityReweighter\n",
    "\n",
    "grid_values = {'n_estimators': [30, 100], \n",
    "               'learning_rate':[0.01, 0.001, 0.009],\n",
    "               'max_depth': [5, 10],\n",
    "               'min_samples_leaf': [1, 10, 100]}\n",
    "\n",
    "pr = PropensityReweighter(config)\n",
    "best_predictor = pr.fit_gridsearch(original, target, grid_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06094ff2-1ed8-46ed-ae8d-747b702045d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.30878491, 5.73613099, 2.28492   , 6.115655  , 5.32396158,\n",
       "       1.85894275, 1.92759861, 2.58848909, 6.07864215, 1.93103268])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weights = best_predictor.predict(target)\n",
    "best_weights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c3788b-af08-427b-acb4-291f0401b2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'predicted weights')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(best_weights, bins=50)\n",
    "plt.yscale('log')\n",
    "plt.title('predicted weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6aeac7-558f-4f86-a0b6-e62098313a1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## future's and past's analysis from QA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa36b22-cb5c-414e-a269-92cde768970e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80b40864a0a4e54b4f443111a55ab5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a255055af824d0aa025174c8bcc4ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.4471\n",
      "Mean EMD on non-weighted test data: 0.1307\n",
      "Mean ED on non-weighted test data: 0.2591\n",
      "\n",
      "Mean k2 on weighted test data: 0.3759\n",
      "Mean EMD on weighted test data: 0.0991\n",
      "Mean ED on weighted test data: 0.2025\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915376d0af7f40dd8eca0caa82931cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.5446\n",
      "Mean EMD on non-weighted test data: 0.1587\n",
      "Mean ED on non-weighted test data: 0.3206\n",
      "\n",
      "Mean k2 on weighted test data: 0.5297\n",
      "Mean EMD on weighted test data: 0.153\n",
      "Mean ED on weighted test data: 0.3087\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0338c83ec1454db450fff1922697ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.6295\n",
      "Mean EMD on non-weighted test data: 0.1695\n",
      "Mean ED on non-weighted test data: 0.3596\n",
      "\n",
      "Mean k2 on weighted test data: 0.6033\n",
      "Mean EMD on weighted test data: 0.1593\n",
      "Mean ED on weighted test data: 0.3366\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba1e58a950d4d91b56f16224ea2ca98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.615\n",
      "Mean EMD on non-weighted test data: 0.1625\n",
      "Mean ED on non-weighted test data: 0.3474\n",
      "\n",
      "Mean k2 on weighted test data: 0.6\n",
      "Mean EMD on weighted test data: 0.1599\n",
      "Mean ED on weighted test data: 0.3383\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x7fd715d088b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tqdm/std.py\", line 1161, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original = texts[texts[\"unit\"] == 'original'][\"Question\"].tolist()\n",
    "\n",
    "results = {}\n",
    "for i in tqdm(range(1, 8)):\n",
    "    cur_shift = f'past-{i}'\n",
    "    target = texts[texts[\"unit\"] == cur_shift][\"Question\"].tolist()\n",
    "    target_train, target_test  = target[:len(target) // 3], target[len(target) // 3:]\n",
    "    labels = [texts[texts[\"unit\"] == cur_shift][\"gpt3_is_correct\"].tolist()[len(target) // 3:],\n",
    "             texts[texts[\"unit\"] == cur_shift][\"gpt4_is_correct\"].tolist()[len(target) // 3:],\n",
    "             texts[texts[\"unit\"] == cur_shift][\"llama2_is_correct\"].tolist()[len(target) // 3:],\n",
    "             texts[texts[\"unit\"] == cur_shift][\"llama3_is_correct\"].tolist()[len(target) // 3:]]\n",
    "    \n",
    "    grid_values = {'n_estimators': [30, 100], \n",
    "               'learning_rate':[0.01, 0.001, 0.009],\n",
    "               'max_depth': [5, 10],\n",
    "               'min_samples_leaf': [1, 10, 100]}\n",
    "\n",
    "    pr = PropensityReweighter(config)\n",
    "    best_predictor = pr.fit_gridsearch(original, target_train, grid_values)\n",
    "    \n",
    "    best_weights = best_predictor.predict(target_test)\n",
    "    \n",
    "    accuracy_all = []\n",
    "    f1_all = []\n",
    "    f1_all.append(f\"{len(target_train)} / {len(target_test)}\")\n",
    "    for model_pred in labels:\n",
    "        # ac = round(accuracy_score([1] * len(model_pred), model_pred), 3), round(accuracy_score([1] * len(model_pred), model_pred, sample_weight=best_weights), 3)\n",
    "        f1 = round(f1_score([1] * len(model_pred), model_pred), 3), round(f1_score([1] * len(model_pred), model_pred, sample_weight=best_weights), 3)\n",
    "        \n",
    "        # accuracy_all.append(f\"{ac[0]} - {ac[1]}\")\n",
    "        f1_all.append(f\"{f1[0]} / {f1[1]}\")\n",
    "        \n",
    "    # results[cur_shift] = {'accuracy': accuracy_all, 'f1-score': f1_all}\n",
    "    results[cur_shift] = {'f1-score': f1_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f13d2b-e0a3-4e16-a2ed-3bf572b9c648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([], columns=[\"shift\", \"num_samples\", \"f1_gpt3\", \"f1_gpt4\", \"f1_llama2\", \"f1_llama3\"])\n",
    "\n",
    "for item in results:\n",
    "    df = pd.concat(\n",
    "        [df, pd.DataFrame([[item, results[item][\"f1-score\"][0],\n",
    "                            results[item][\"f1-score\"][1], \n",
    "                            results[item][\"f1-score\"][2], \n",
    "                            results[item][\"f1-score\"][3],\n",
    "                            results[item][\"f1-score\"][4]]], columns=[\"shift\", \"num_samples\", \"f1_gpt3\", \"f1_gpt4\", \"f1_llama2\", \"f1_llama3\"])],\n",
    "        ignore_index=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8fc6671-c72e-46cf-8150-f71fd156f030",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>f1_gpt3</th>\n",
       "      <th>f1_gpt4</th>\n",
       "      <th>f1_llama2</th>\n",
       "      <th>f1_llama3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>future+1</td>\n",
       "      <td>10 / 22</td>\n",
       "      <td>0.872 / 0.868</td>\n",
       "      <td>0.778 / 0.815</td>\n",
       "      <td>0.429 / 0.509</td>\n",
       "      <td>0.625 / 0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>future+2</td>\n",
       "      <td>7 / 15</td>\n",
       "      <td>0.846 / 0.836</td>\n",
       "      <td>0.929 / 0.913</td>\n",
       "      <td>0.571 / 0.609</td>\n",
       "      <td>0.696 / 0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>future+3</td>\n",
       "      <td>5 / 12</td>\n",
       "      <td>0.857 / 0.733</td>\n",
       "      <td>0.8 / 0.715</td>\n",
       "      <td>0.4 / 0.349</td>\n",
       "      <td>0.588 / 0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>future+4</td>\n",
       "      <td>4 / 8</td>\n",
       "      <td>0.857 / 0.58</td>\n",
       "      <td>0.769 / 0.895</td>\n",
       "      <td>0.222 / 0.176</td>\n",
       "      <td>0.769 / 0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>future+5</td>\n",
       "      <td>3 / 8</td>\n",
       "      <td>0.857 / 0.862</td>\n",
       "      <td>0.667 / 0.674</td>\n",
       "      <td>0.545 / 0.486</td>\n",
       "      <td>0.667 / 0.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>future+6</td>\n",
       "      <td>3 / 6</td>\n",
       "      <td>0.8 / 0.799</td>\n",
       "      <td>0.667 / 0.633</td>\n",
       "      <td>0.5 / 0.482</td>\n",
       "      <td>0.5 / 0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>future+7</td>\n",
       "      <td>2 / 6</td>\n",
       "      <td>0.8 / 0.855</td>\n",
       "      <td>0.909 / 0.927</td>\n",
       "      <td>0.667 / 0.758</td>\n",
       "      <td>0.8 / 0.855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      shift num_samples        f1_gpt3        f1_gpt4      f1_llama2  \\\n",
       "0  future+1     10 / 22  0.872 / 0.868  0.778 / 0.815  0.429 / 0.509   \n",
       "1  future+2      7 / 15  0.846 / 0.836  0.929 / 0.913  0.571 / 0.609   \n",
       "2  future+3      5 / 12  0.857 / 0.733    0.8 / 0.715    0.4 / 0.349   \n",
       "3  future+4       4 / 8   0.857 / 0.58  0.769 / 0.895  0.222 / 0.176   \n",
       "4  future+5       3 / 8  0.857 / 0.862  0.667 / 0.674  0.545 / 0.486   \n",
       "5  future+6       3 / 6    0.8 / 0.799  0.667 / 0.633    0.5 / 0.482   \n",
       "6  future+7       2 / 6    0.8 / 0.855  0.909 / 0.927  0.667 / 0.758   \n",
       "\n",
       "       f1_llama3  \n",
       "0  0.625 / 0.406  \n",
       "1  0.696 / 0.681  \n",
       "2  0.588 / 0.568  \n",
       "3  0.769 / 0.893  \n",
       "4  0.667 / 0.674  \n",
       "5    0.5 / 0.482  \n",
       "6    0.8 / 0.855  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_test\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "766daef1-499d-4423-94aa-a0abbe719f77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>f1_gpt3</th>\n",
       "      <th>f1_gpt4</th>\n",
       "      <th>f1_llama2</th>\n",
       "      <th>f1_llama3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>past-1</td>\n",
       "      <td>6 / 14</td>\n",
       "      <td>0.923 / 0.942</td>\n",
       "      <td>0.923 / 0.837</td>\n",
       "      <td>0.526 / 0.491</td>\n",
       "      <td>0.783 / 0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>past-2</td>\n",
       "      <td>4 / 9</td>\n",
       "      <td>0.8 / 0.684</td>\n",
       "      <td>0.875 / 0.761</td>\n",
       "      <td>0.615 / 0.512</td>\n",
       "      <td>0.364 / 0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>past-3</td>\n",
       "      <td>3 / 6</td>\n",
       "      <td>0.8 / 0.825</td>\n",
       "      <td>0.8 / 0.825</td>\n",
       "      <td>0.0 / 0.0</td>\n",
       "      <td>0.667 / 0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>past-4</td>\n",
       "      <td>3 / 6</td>\n",
       "      <td>0.8 / 0.81</td>\n",
       "      <td>0.8 / 0.81</td>\n",
       "      <td>0.286 / 0.235</td>\n",
       "      <td>0.8 / 0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>past-5</td>\n",
       "      <td>1 / 4</td>\n",
       "      <td>0.667 / 0.443</td>\n",
       "      <td>0.857 / 0.787</td>\n",
       "      <td>0.0 / 0.0</td>\n",
       "      <td>0.4 / 0.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>past-6</td>\n",
       "      <td>1 / 2</td>\n",
       "      <td>0.667 / 0.447</td>\n",
       "      <td>0.667 / 0.447</td>\n",
       "      <td>0.0 / 0.0</td>\n",
       "      <td>0.667 / 0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>past-7</td>\n",
       "      <td>1 / 2</td>\n",
       "      <td>0.667 / 0.845</td>\n",
       "      <td>0.667 / 0.845</td>\n",
       "      <td>0.0 / 0.0</td>\n",
       "      <td>0.667 / 0.845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    shift num_samples        f1_gpt3        f1_gpt4      f1_llama2  \\\n",
       "0  past-1      6 / 14  0.923 / 0.942  0.923 / 0.837  0.526 / 0.491   \n",
       "1  past-2       4 / 9    0.8 / 0.684  0.875 / 0.761  0.615 / 0.512   \n",
       "2  past-3       3 / 6    0.8 / 0.825    0.8 / 0.825      0.0 / 0.0   \n",
       "3  past-4       3 / 6     0.8 / 0.81     0.8 / 0.81  0.286 / 0.235   \n",
       "4  past-5       1 / 4  0.667 / 0.443  0.857 / 0.787      0.0 / 0.0   \n",
       "5  past-6       1 / 2  0.667 / 0.447  0.667 / 0.447      0.0 / 0.0   \n",
       "6  past-7       1 / 2  0.667 / 0.845  0.667 / 0.845      0.0 / 0.0   \n",
       "\n",
       "       f1_llama3  \n",
       "0  0.783 / 0.746  \n",
       "1  0.364 / 0.291  \n",
       "2  0.667 / 0.688  \n",
       "3     0.8 / 0.81  \n",
       "4    0.4 / 0.249  \n",
       "5  0.667 / 0.447  \n",
       "6  0.667 / 0.845  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# past_test\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "474f5d98-5c83-4c41-8e79-7ac9cf0c6cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([], columns=[\"shift\", \"f1_gpt3\", \"f1_gpt4\", \"f1_llama2\", \"f1_llama3\"])\n",
    "\n",
    "for item in results:\n",
    "    df = pd.concat(\n",
    "        [df, pd.DataFrame([[item, results[item][\"f1-score\"][0],\n",
    "                            results[item][\"f1-score\"][1], \n",
    "                            results[item][\"f1-score\"][2], \n",
    "                            results[item][\"f1-score\"][3]]], columns=[\"shift\", \"f1_gpt3\", \"f1_gpt4\", \"f1_llama2\", \"f1_llama3\"])],\n",
    "        ignore_index=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb39c1e-58fe-4aaa-9a94-4d69d2ff3329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift</th>\n",
       "      <th>f1_gpt3</th>\n",
       "      <th>f1_gpt4</th>\n",
       "      <th>f1_llama2</th>\n",
       "      <th>f1_llama3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>past-1</td>\n",
       "      <td>0.857 / 0.939</td>\n",
       "      <td>0.824 / 0.832</td>\n",
       "      <td>0.462 / 0.567</td>\n",
       "      <td>0.788 / 0.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>past-2</td>\n",
       "      <td>0.818 / 0.916</td>\n",
       "      <td>0.762 / 0.851</td>\n",
       "      <td>0.471 / 0.659</td>\n",
       "      <td>0.471 / 0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>past-3</td>\n",
       "      <td>0.8 / 0.905</td>\n",
       "      <td>0.714 / 0.841</td>\n",
       "      <td>0.0 / 0.617</td>\n",
       "      <td>0.8 / 0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>past-4</td>\n",
       "      <td>0.8 / 0.906</td>\n",
       "      <td>0.714 / 0.84</td>\n",
       "      <td>0.5 / 0.63</td>\n",
       "      <td>0.714 / 0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>past-5</td>\n",
       "      <td>0.75 / 0.934</td>\n",
       "      <td>0.889 / 0.835</td>\n",
       "      <td>0.0 / 0.467</td>\n",
       "      <td>0.333 / 0.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>past-6</td>\n",
       "      <td>0.8 / 0.92</td>\n",
       "      <td>0.8 / 0.84</td>\n",
       "      <td>0.0 / 0.625</td>\n",
       "      <td>0.8 / 0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>past-7</td>\n",
       "      <td>0.5 / 0.865</td>\n",
       "      <td>0.8 / 0.79</td>\n",
       "      <td>0.0 / 0.552</td>\n",
       "      <td>0.5 / 0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    shift        f1_gpt3        f1_gpt4      f1_llama2      f1_llama3\n",
       "0  past-1  0.857 / 0.939  0.824 / 0.832  0.462 / 0.567  0.788 / 0.594\n",
       "1  past-2  0.818 / 0.916  0.762 / 0.851  0.471 / 0.659  0.471 / 0.661\n",
       "2  past-3    0.8 / 0.905  0.714 / 0.841    0.0 / 0.617    0.8 / 0.658\n",
       "3  past-4    0.8 / 0.906   0.714 / 0.84     0.5 / 0.63  0.714 / 0.659\n",
       "4  past-5   0.75 / 0.934  0.889 / 0.835    0.0 / 0.467  0.333 / 0.523\n",
       "5  past-6     0.8 / 0.92     0.8 / 0.84    0.0 / 0.625    0.8 / 0.752\n",
       "6  past-7    0.5 / 0.865     0.8 / 0.79    0.0 / 0.552    0.5 / 0.625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5552cc9e-9ea1-4392-b31e-a31f6b0fe0bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## future's and past's analysis from updated QA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65bfff50-7e26-4270-ab03-46655d470b06",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96311d23b164bb197d8126f3a017f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e48977dc8a4bb0b2b651dbd5ca13ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.0876\n",
      "Mean EMD on non-weighted test data: 0.0196\n",
      "Mean ED on non-weighted test data: 0.0393\n",
      "\n",
      "Mean k2 on weighted test data: 0.0873\n",
      "Mean EMD on weighted test data: 0.0196\n",
      "Mean ED on weighted test data: 0.039\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31c6f6fb74f465683a46a49fb535cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.107\n",
      "Mean EMD on non-weighted test data: 0.0256\n",
      "Mean ED on non-weighted test data: 0.0504\n",
      "\n",
      "Mean k2 on weighted test data: 0.1043\n",
      "Mean EMD on weighted test data: 0.0248\n",
      "Mean ED on weighted test data: 0.0488\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ad50c0f64b443f9027b1cb7ff85ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.1252\n",
      "Mean EMD on non-weighted test data: 0.0322\n",
      "Mean ED on non-weighted test data: 0.0622\n",
      "\n",
      "Mean k2 on weighted test data: 0.122\n",
      "Mean EMD on weighted test data: 0.0311\n",
      "Mean ED on weighted test data: 0.0601\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778d7942eb1f4df089b9217e6cc0d799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.1319\n",
      "Mean EMD on non-weighted test data: 0.0346\n",
      "Mean ED on non-weighted test data: 0.0662\n",
      "\n",
      "Mean k2 on weighted test data: 0.1295\n",
      "Mean EMD on weighted test data: 0.033\n",
      "Mean ED on weighted test data: 0.0633\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835f2834cc3d45929a5fb48c0764a261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.1422\n",
      "Mean EMD on non-weighted test data: 0.0374\n",
      "Mean ED on non-weighted test data: 0.0716\n",
      "\n",
      "Mean k2 on weighted test data: 0.1367\n",
      "Mean EMD on weighted test data: 0.0354\n",
      "Mean ED on weighted test data: 0.0681\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c9374537b244a4aaaf79c4d049fcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.1716\n",
      "Mean EMD on non-weighted test data: 0.0479\n",
      "Mean ED on non-weighted test data: 0.0911\n",
      "\n",
      "Mean k2 on weighted test data: 0.1597\n",
      "Mean EMD on weighted test data: 0.0425\n",
      "Mean ED on weighted test data: 0.0812\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ebd7b1657a412d8e3a7f9164a47ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.2084\n",
      "Mean EMD on non-weighted test data: 0.0584\n",
      "Mean ED on non-weighted test data: 0.1119\n",
      "\n",
      "Mean k2 on weighted test data: 0.2018\n",
      "Mean EMD on weighted test data: 0.053\n",
      "Mean ED on weighted test data: 0.103\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194b3a909feb4362ae6b69adb443a3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.2674\n",
      "Mean EMD on non-weighted test data: 0.0736\n",
      "Mean ED on non-weighted test data: 0.1418\n",
      "\n",
      "Mean k2 on weighted test data: 0.2551\n",
      "Mean EMD on weighted test data: 0.0678\n",
      "Mean ED on weighted test data: 0.1315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original = texts[texts[\"Unit\"] == 'Original'][\"Question\"].tolist()\n",
    "labels = [texts[texts[\"Unit\"] == 'Original'][\"gpt4score\"].tolist(),\n",
    "             texts[texts[\"Unit\"] == 'Original'][\"gpt3.5score\"].tolist()]\n",
    "\n",
    "results = {}\n",
    "for i in tqdm(range(1, 9)):\n",
    "    cur_shift = f'Future+{i}'\n",
    "    target = texts[texts[\"Unit\"] == cur_shift][\"Question\"].tolist()\n",
    "    true_target_labels = [texts[texts[\"Unit\"] == cur_shift][\"gpt4score\"].tolist(),\n",
    "             texts[texts[\"Unit\"] == cur_shift][\"gpt3.5score\"].tolist()]\n",
    "    \n",
    "    grid_values = {'n_estimators': [30, 100], \n",
    "               'learning_rate':[0.01, 0.001, 0.009],\n",
    "               'max_depth': [5, 10],\n",
    "               'min_samples_leaf': [1, 10, 100]}\n",
    "\n",
    "    pr = PropensityReweighter(config)\n",
    "    best_predictor = pr.fit_gridsearch(original, target, grid_values)\n",
    "    \n",
    "    best_weights = best_predictor.predict(original)\n",
    "    \n",
    "    accuracy_all = []\n",
    "    f1_all = []\n",
    "    f1_all.append(f\"{len(target)}\")\n",
    "    for j, model_pred in enumerate(labels):\n",
    "        f1 = round(f1_score([5] * len(true_target_labels[j]), true_target_labels[j], sample_weight=([1] * len(true_target_labels[j])), average='weighted'), 3), round(f1_score([5] * len(model_pred), model_pred, sample_weight=best_weights, average='weighted'), 3)\n",
    "        f1_all.append(f\"{f1[0]} / {f1[1]}\")\n",
    "        \n",
    "    results[cur_shift] = {'f1-score': f1_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9403f4a-c024-4263-aa01-4fefe77af534",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([], columns=[\"shift\", \"num_samples\", \"f1_gpt4\", \"f1_gpt3.5\"])\n",
    "\n",
    "for item in results:\n",
    "    df = pd.concat(\n",
    "        [df, pd.DataFrame([[item, results[item][\"f1-score\"][0],\n",
    "                            results[item][\"f1-score\"][1], \n",
    "                            results[item][\"f1-score\"][2]]], columns=[\"shift\", \"num_samples\", \"f1_gpt4\", \"f1_gpt3.5\"])],\n",
    "        ignore_index=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac80d148-78c1-4e64-8c23-5b825bb5fb18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>f1_gpt4</th>\n",
       "      <th>f1_gpt3.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Future+1</td>\n",
       "      <td>61</td>\n",
       "      <td>0.948 / 0.957</td>\n",
       "      <td>0.957 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Future+2</td>\n",
       "      <td>57</td>\n",
       "      <td>0.954 / 0.954</td>\n",
       "      <td>0.982 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Future+3</td>\n",
       "      <td>54</td>\n",
       "      <td>0.941 / 0.953</td>\n",
       "      <td>0.909 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Future+4</td>\n",
       "      <td>44</td>\n",
       "      <td>0.952 / 0.938</td>\n",
       "      <td>0.952 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Future+5</td>\n",
       "      <td>42</td>\n",
       "      <td>0.95 / 0.961</td>\n",
       "      <td>0.95 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Future+6</td>\n",
       "      <td>35</td>\n",
       "      <td>0.923 / 0.955</td>\n",
       "      <td>0.906 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Future+7</td>\n",
       "      <td>25</td>\n",
       "      <td>0.98 / 0.901</td>\n",
       "      <td>0.913 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Future+8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.889 / 0.937</td>\n",
       "      <td>1.0 / 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      shift num_samples        f1_gpt4    f1_gpt3.5\n",
       "0  Future+1          61  0.948 / 0.957  0.957 / 1.0\n",
       "1  Future+2          57  0.954 / 0.954  0.982 / 1.0\n",
       "2  Future+3          54  0.941 / 0.953  0.909 / 1.0\n",
       "3  Future+4          44  0.952 / 0.938  0.952 / 1.0\n",
       "4  Future+5          42   0.95 / 0.961   0.95 / 1.0\n",
       "5  Future+6          35  0.923 / 0.955  0.906 / 1.0\n",
       "6  Future+7          25   0.98 / 0.901  0.913 / 1.0\n",
       "7  Future+8          10  0.889 / 0.937    1.0 / 1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # future shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d76cfba8-fa7c-400d-90d5-44abbfe240d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>f1_gpt4</th>\n",
       "      <th>f1_gpt3.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Past-1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.957 / 0.958</td>\n",
       "      <td>0.947 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Past-2</td>\n",
       "      <td>54</td>\n",
       "      <td>0.962 / 0.959</td>\n",
       "      <td>0.931 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Past-3</td>\n",
       "      <td>53</td>\n",
       "      <td>0.971 / 0.954</td>\n",
       "      <td>0.929 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Past-4</td>\n",
       "      <td>44</td>\n",
       "      <td>0.965 / 0.951</td>\n",
       "      <td>0.977 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Past-5</td>\n",
       "      <td>41</td>\n",
       "      <td>0.921 / 0.947</td>\n",
       "      <td>0.962 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Past-6</td>\n",
       "      <td>32</td>\n",
       "      <td>0.915 / 0.939</td>\n",
       "      <td>0.933 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Past-7</td>\n",
       "      <td>24</td>\n",
       "      <td>0.909 / 0.957</td>\n",
       "      <td>0.979 / 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Past-8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0 / 0.954</td>\n",
       "      <td>1.0 / 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    shift num_samples        f1_gpt4    f1_gpt3.5\n",
       "0  Past-1          60  0.957 / 0.958  0.947 / 1.0\n",
       "1  Past-2          54  0.962 / 0.959  0.931 / 1.0\n",
       "2  Past-3          53  0.971 / 0.954  0.929 / 1.0\n",
       "3  Past-4          44  0.965 / 0.951  0.977 / 1.0\n",
       "4  Past-5          41  0.921 / 0.947  0.962 / 1.0\n",
       "5  Past-6          32  0.915 / 0.939  0.933 / 1.0\n",
       "6  Past-7          24  0.909 / 0.957  0.979 / 1.0\n",
       "7  Past-8           8    1.0 / 0.954    1.0 / 1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # past shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8830d-7d41-41ef-887c-b0426af6d543",
   "metadata": {},
   "source": [
    "## wmt en-de metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82794010-99b8-45a4-8517-91dfd19f9409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./propensity_reweighting/config/config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "data = pd.read_csv('./llm_propensity/evalualtion_metrics/wmt23/en-de.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec7f1db-0eeb-4910-9614-6bf9a074ca2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_sentence</th>\n",
       "      <th>human_translate</th>\n",
       "      <th>model1</th>\n",
       "      <th>model1_score</th>\n",
       "      <th>model2</th>\n",
       "      <th>model2_score</th>\n",
       "      <th>model3</th>\n",
       "      <th>model3_score</th>\n",
       "      <th>model4</th>\n",
       "      <th>model4_score</th>\n",
       "      <th>...</th>\n",
       "      <th>model8</th>\n",
       "      <th>model8_score</th>\n",
       "      <th>model9</th>\n",
       "      <th>model9_score</th>\n",
       "      <th>model10</th>\n",
       "      <th>model10_score</th>\n",
       "      <th>model11</th>\n",
       "      <th>model11_score</th>\n",
       "      <th>model12</th>\n",
       "      <th>model12_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police arrest 15 after violent protest outside...</td>\n",
       "      <td>Polizei verhaftet 15 Menschen nach gewaltttig...</td>\n",
       "      <td>Polizei verhaftet 15 nach gewaltttigem Protes...</td>\n",
       "      <td>14.448815</td>\n",
       "      <td>Die Polizei nimmt 15 Personen nach gewaltttig...</td>\n",
       "      <td>19.674980</td>\n",
       "      <td>Die Polizei verhaftet 15 Personen nach gewalts...</td>\n",
       "      <td>16.590387</td>\n",
       "      <td>Polizei verhaftet 15 nach gewaltttigem Protes...</td>\n",
       "      <td>14.448815</td>\n",
       "      <td>...</td>\n",
       "      <td>Polizei verhaftet 15 Personen nach gewaltttig...</td>\n",
       "      <td>14.530346</td>\n",
       "      <td>Polizeiverhaftung 15 nach gewaltsamen Protest...</td>\n",
       "      <td>4.495987</td>\n",
       "      <td>Polizei nimmt 15 nach gewaltttigen Protesten ...</td>\n",
       "      <td>23.801761</td>\n",
       "      <td>Polizei nimmt 15 Personen nach gewaltsamen Pro...</td>\n",
       "      <td>8.516593</td>\n",
       "      <td>Polizei verhaftet 15 nach gewaltttigem Protes...</td>\n",
       "      <td>14.448815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The incident comes after increase in numbers o...</td>\n",
       "      <td>Der Vorfall ereignet sich, nachdem sich die Za...</td>\n",
       "      <td>Der Vorfall ereignete sich nach einem Anstieg ...</td>\n",
       "      <td>26.303375</td>\n",
       "      <td>Der Vorfall ereignete sich nach einem Anstieg ...</td>\n",
       "      <td>29.545219</td>\n",
       "      <td>Der Vorfall ereignete sich, nachdem die Zahl d...</td>\n",
       "      <td>36.649802</td>\n",
       "      <td>Der Vorfall kommt nach einer Zunahme der Zahl ...</td>\n",
       "      <td>25.154173</td>\n",
       "      <td>...</td>\n",
       "      <td>Der Vorfall ereignete sich, nachdem die Zahl d...</td>\n",
       "      <td>34.150705</td>\n",
       "      <td>Die Polizei sagte, dass ein Polizist und zwei ...</td>\n",
       "      <td>14.294320</td>\n",
       "      <td>Der Vorfall ereignete sich, nachdem die Zahl d...</td>\n",
       "      <td>28.939657</td>\n",
       "      <td>Der Vorfall ereignete sich, nachdem die Zahl d...</td>\n",
       "      <td>30.218550</td>\n",
       "      <td>Der Vorfall ereignete sich nach einem Anstieg ...</td>\n",
       "      <td>27.196164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Home Office has been using the hotel to te...</td>\n",
       "      <td>Das Innenministerium hat das Hotel seit letzte...</td>\n",
       "      <td>Das Innenministerium nutzt das Hotel laut loka...</td>\n",
       "      <td>34.035510</td>\n",
       "      <td>Das Innenministerium nutzt das Hotel seit letz...</td>\n",
       "      <td>35.119677</td>\n",
       "      <td>Laut lokalen Medien nutzt das Innenministerium...</td>\n",
       "      <td>45.395746</td>\n",
       "      <td>Das Innenministerium nutzt das Hotel seit letz...</td>\n",
       "      <td>40.719846</td>\n",
       "      <td>...</td>\n",
       "      <td>Lokalen Medien zufolge nutzt das Innenminister...</td>\n",
       "      <td>39.641643</td>\n",
       "      <td>Das Home Office nutzt das Hotel seit letztem J...</td>\n",
       "      <td>42.385532</td>\n",
       "      <td>Das Innenministerium nutzt das Hotel seit letz...</td>\n",
       "      <td>36.082066</td>\n",
       "      <td>Lokalen Medien zufolge nutzt das Innenminister...</td>\n",
       "      <td>29.267528</td>\n",
       "      <td>Lokalen Medien zufolge nutzt das Innenminister...</td>\n",
       "      <td>34.067354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>More than 45,000 people reached the UK by that...</td>\n",
       "      <td>Mehr als 45.000 Menschen haben 2022 Grobritan...</td>\n",
       "      <td>Mehr als 45.000 Menschen erreichten 2022 auf d...</td>\n",
       "      <td>46.062127</td>\n",
       "      <td>Mehr als 45.000 Menschen erreichten das Verein...</td>\n",
       "      <td>48.566785</td>\n",
       "      <td>Mehr als 45.000 Menschen erreichten 2022 auf d...</td>\n",
       "      <td>47.026292</td>\n",
       "      <td>Mehr als 45.000 Menschen erreichten Grobritan...</td>\n",
       "      <td>42.405909</td>\n",
       "      <td>...</td>\n",
       "      <td>Im Jahr 2022 erreichten mehr als 45.000 Mensch...</td>\n",
       "      <td>34.104278</td>\n",
       "      <td>Das System zur Prfung von Asylantrgen hat si...</td>\n",
       "      <td>26.445337</td>\n",
       "      <td>Mehr als 45.000 Menschen erreichten das Verein...</td>\n",
       "      <td>26.969867</td>\n",
       "      <td>Im Jahr 2022 erreichten mehr als 45.000 Mensch...</td>\n",
       "      <td>37.961820</td>\n",
       "      <td>ber 45.000 Menschen erreichten das Vereinigte...</td>\n",
       "      <td>33.754834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>President's Cup: Candystripes defeat Rovers in...</td>\n",
       "      <td>President's Cup: Candystripes besiegen Rovers ...</td>\n",
       "      <td>President's Cup: Candystripes besiegen Rovers ...</td>\n",
       "      <td>58.143074</td>\n",
       "      <td>President's Cup: Candystripes besiegen Rovers ...</td>\n",
       "      <td>58.143074</td>\n",
       "      <td>President's Cup: Candystripes besiegen Rovers ...</td>\n",
       "      <td>58.143074</td>\n",
       "      <td>President's Cup: Candystripes besiegen Rovers ...</td>\n",
       "      <td>58.143074</td>\n",
       "      <td>...</td>\n",
       "      <td>President's Cup: Candystripes besiegen Rovers ...</td>\n",
       "      <td>58.143074</td>\n",
       "      <td>President's Cup: Candystripes besiegen Rovers ...</td>\n",
       "      <td>57.212484</td>\n",
       "      <td>President's Cup: Candystripes besiegen Rovers ...</td>\n",
       "      <td>58.143074</td>\n",
       "      <td>President's Cup: Candystripes besiegen Rovers ...</td>\n",
       "      <td>58.143074</td>\n",
       "      <td>President's Cup: Candystripes besiegen Rovers ...</td>\n",
       "      <td>58.143074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Ergonomic and affordable, but not very toleran...</td>\n",
       "      <td>Ergonomisch und gnstig, aber nicht fr die ko...</td>\n",
       "      <td>Ergonomisch und erschwinglich, aber nicht sehr...</td>\n",
       "      <td>17.542198</td>\n",
       "      <td>Ergonomisch und erschwinglich, aber nicht sehr...</td>\n",
       "      <td>18.360281</td>\n",
       "      <td>Ergonomisch und erschwinglich, aber nicht sehr...</td>\n",
       "      <td>17.542198</td>\n",
       "      <td>Ergonomisch und erschwinglich, aber nicht sehr...</td>\n",
       "      <td>17.542198</td>\n",
       "      <td>...</td>\n",
       "      <td>Ergonomisch und erschwinglich, aber nicht sehr...</td>\n",
       "      <td>17.542198</td>\n",
       "      <td>Ergonomisch und erschwinglich, aber nicht sehr...</td>\n",
       "      <td>18.360281</td>\n",
       "      <td>Ergonomisch und erschwinglich, aber nicht sehr...</td>\n",
       "      <td>17.542198</td>\n",
       "      <td>Ergonomisch und erschwinglich, aber nicht sehr...</td>\n",
       "      <td>17.542198</td>\n",
       "      <td>Ergonomisch und erschwinglich, aber wenig tole...</td>\n",
       "      <td>10.738977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>It has a slimmer design shape that fits better...</td>\n",
       "      <td>Der Controller hat ein schmaleres Design, das ...</td>\n",
       "      <td>Es hat eine schlankere Designform, die besser ...</td>\n",
       "      <td>32.344238</td>\n",
       "      <td>Es hat ein schlankeres Design, das besser in d...</td>\n",
       "      <td>31.351857</td>\n",
       "      <td>Er hat ein schlankeres Design, das besser in d...</td>\n",
       "      <td>35.118605</td>\n",
       "      <td>Es hat eine schlankere Designform, die besser ...</td>\n",
       "      <td>31.718754</td>\n",
       "      <td>...</td>\n",
       "      <td>Das schlankere Design liegt besser in der Hand...</td>\n",
       "      <td>28.587270</td>\n",
       "      <td>Es hat eine schlankere Konstruktionsform, die ...</td>\n",
       "      <td>24.698036</td>\n",
       "      <td>Es hat eine schlankere Designform, die besser ...</td>\n",
       "      <td>30.391731</td>\n",
       "      <td>Er hat eine schlankere Form, die besser in der...</td>\n",
       "      <td>38.505105</td>\n",
       "      <td>Er hat ein schlankeres Design, das besser in d...</td>\n",
       "      <td>25.012669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>You get what you pay for</td>\n",
       "      <td>Man kriegt, wofr man bezahlt</td>\n",
       "      <td>Sie bekommen, wofr Sie bezahlen</td>\n",
       "      <td>16.233396</td>\n",
       "      <td>Man bekommt, wofr man bezahlt.</td>\n",
       "      <td>43.472087</td>\n",
       "      <td>Du bekommst, wofr du bezahlst</td>\n",
       "      <td>16.233396</td>\n",
       "      <td>Du bekommst, wofr du bezahlst</td>\n",
       "      <td>16.233396</td>\n",
       "      <td>...</td>\n",
       "      <td>Sie bekommen, wofr Sie bezahlen</td>\n",
       "      <td>16.233396</td>\n",
       "      <td>Du bekommst, wofr du zahlst</td>\n",
       "      <td>16.233396</td>\n",
       "      <td>Du bekommst, wofr du bezahlst</td>\n",
       "      <td>16.233396</td>\n",
       "      <td>Sie bekommen, wofr Sie bezahlen</td>\n",
       "      <td>16.233396</td>\n",
       "      <td>Sie bekommen, wofr Sie zahlen</td>\n",
       "      <td>16.233396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>I was disappointed upon receiving this item as...</td>\n",
       "      <td>Ich war sehr enttuscht, als ich den Artikel e...</td>\n",
       "      <td>Ich war enttuscht, als ich diesen Artikel erh...</td>\n",
       "      <td>31.972716</td>\n",
       "      <td>Ich war enttuscht, als ich diesen Artikel erh...</td>\n",
       "      <td>32.594279</td>\n",
       "      <td>Ich war enttuscht, als ich diesen Artikel erh...</td>\n",
       "      <td>29.134569</td>\n",
       "      <td>Ich war enttuscht, als ich diesen Artikel erh...</td>\n",
       "      <td>25.972745</td>\n",
       "      <td>...</td>\n",
       "      <td>Ich war enttuscht, als ich diesen Artikel erh...</td>\n",
       "      <td>28.188503</td>\n",
       "      <td>Ich war enttuscht darber, dass der silberne ...</td>\n",
       "      <td>20.855679</td>\n",
       "      <td>Ich war enttuscht, als ich diesen Artikel erh...</td>\n",
       "      <td>25.673215</td>\n",
       "      <td>Ich war enttuscht, als ich diesen Artikel erh...</td>\n",
       "      <td>30.392323</td>\n",
       "      <td>Ich war enttuscht, als ich diesen Artikel erh...</td>\n",
       "      <td>25.508720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>Nothing like the previous Stylo phones, MASSIV...</td>\n",
       "      <td>Kein Vergleich zu den vorherigen Stylo-Handys,...</td>\n",
       "      <td>Nichts wie die vorherigen Stylo-Telefone, MASS...</td>\n",
       "      <td>30.134798</td>\n",
       "      <td>Nichts wie die vorherigen Stylo-Telefone, EINE...</td>\n",
       "      <td>34.747283</td>\n",
       "      <td>Nichts wie bei den vorherigen Stylo-Telefonen,...</td>\n",
       "      <td>31.891316</td>\n",
       "      <td>Nichts wie die vorherigen Stylo-Telefone, MASS...</td>\n",
       "      <td>32.094305</td>\n",
       "      <td>...</td>\n",
       "      <td>Nichts wie die vorherigen Stylo-Telefone, RIES...</td>\n",
       "      <td>29.319509</td>\n",
       "      <td>Nichts wie die vorherigen Stylo Telefone, MASS...</td>\n",
       "      <td>4.528188</td>\n",
       "      <td>Nichts wie die vorherigen Stylo-Telefone, MASS...</td>\n",
       "      <td>26.854133</td>\n",
       "      <td>Nicht wie die vorherigen Stylo-Handys, MASSIVE...</td>\n",
       "      <td>35.127483</td>\n",
       "      <td>Nichts wie die vorherigen Stylo-Handys, MASSIV...</td>\n",
       "      <td>25.613711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           en_sentence  \\\n",
       "0    Police arrest 15 after violent protest outside...   \n",
       "1    The incident comes after increase in numbers o...   \n",
       "2    The Home Office has been using the hotel to te...   \n",
       "3    More than 45,000 people reached the UK by that...   \n",
       "4    President's Cup: Candystripes defeat Rovers in...   \n",
       "..                                                 ...   \n",
       "552  Ergonomic and affordable, but not very toleran...   \n",
       "553  It has a slimmer design shape that fits better...   \n",
       "554                           You get what you pay for   \n",
       "555  I was disappointed upon receiving this item as...   \n",
       "556  Nothing like the previous Stylo phones, MASSIV...   \n",
       "\n",
       "                                       human_translate  \\\n",
       "0    Polizei verhaftet 15 Menschen nach gewaltttig...   \n",
       "1    Der Vorfall ereignet sich, nachdem sich die Za...   \n",
       "2    Das Innenministerium hat das Hotel seit letzte...   \n",
       "3    Mehr als 45.000 Menschen haben 2022 Grobritan...   \n",
       "4    President's Cup: Candystripes besiegen Rovers ...   \n",
       "..                                                 ...   \n",
       "552  Ergonomisch und gnstig, aber nicht fr die ko...   \n",
       "553  Der Controller hat ein schmaleres Design, das ...   \n",
       "554                      Man kriegt, wofr man bezahlt   \n",
       "555  Ich war sehr enttuscht, als ich den Artikel e...   \n",
       "556  Kein Vergleich zu den vorherigen Stylo-Handys,...   \n",
       "\n",
       "                                                model1  model1_score  \\\n",
       "0    Polizei verhaftet 15 nach gewaltttigem Protes...     14.448815   \n",
       "1    Der Vorfall ereignete sich nach einem Anstieg ...     26.303375   \n",
       "2    Das Innenministerium nutzt das Hotel laut loka...     34.035510   \n",
       "3    Mehr als 45.000 Menschen erreichten 2022 auf d...     46.062127   \n",
       "4    President's Cup: Candystripes besiegen Rovers ...     58.143074   \n",
       "..                                                 ...           ...   \n",
       "552  Ergonomisch und erschwinglich, aber nicht sehr...     17.542198   \n",
       "553  Es hat eine schlankere Designform, die besser ...     32.344238   \n",
       "554                   Sie bekommen, wofr Sie bezahlen     16.233396   \n",
       "555  Ich war enttuscht, als ich diesen Artikel erh...     31.972716   \n",
       "556  Nichts wie die vorherigen Stylo-Telefone, MASS...     30.134798   \n",
       "\n",
       "                                                model2  model2_score  \\\n",
       "0    Die Polizei nimmt 15 Personen nach gewaltttig...     19.674980   \n",
       "1    Der Vorfall ereignete sich nach einem Anstieg ...     29.545219   \n",
       "2    Das Innenministerium nutzt das Hotel seit letz...     35.119677   \n",
       "3    Mehr als 45.000 Menschen erreichten das Verein...     48.566785   \n",
       "4    President's Cup: Candystripes besiegen Rovers ...     58.143074   \n",
       "..                                                 ...           ...   \n",
       "552  Ergonomisch und erschwinglich, aber nicht sehr...     18.360281   \n",
       "553  Es hat ein schlankeres Design, das besser in d...     31.351857   \n",
       "554                    Man bekommt, wofr man bezahlt.     43.472087   \n",
       "555  Ich war enttuscht, als ich diesen Artikel erh...     32.594279   \n",
       "556  Nichts wie die vorherigen Stylo-Telefone, EINE...     34.747283   \n",
       "\n",
       "                                                model3  model3_score  \\\n",
       "0    Die Polizei verhaftet 15 Personen nach gewalts...     16.590387   \n",
       "1    Der Vorfall ereignete sich, nachdem die Zahl d...     36.649802   \n",
       "2    Laut lokalen Medien nutzt das Innenministerium...     45.395746   \n",
       "3    Mehr als 45.000 Menschen erreichten 2022 auf d...     47.026292   \n",
       "4    President's Cup: Candystripes besiegen Rovers ...     58.143074   \n",
       "..                                                 ...           ...   \n",
       "552  Ergonomisch und erschwinglich, aber nicht sehr...     17.542198   \n",
       "553  Er hat ein schlankeres Design, das besser in d...     35.118605   \n",
       "554                     Du bekommst, wofr du bezahlst     16.233396   \n",
       "555  Ich war enttuscht, als ich diesen Artikel erh...     29.134569   \n",
       "556  Nichts wie bei den vorherigen Stylo-Telefonen,...     31.891316   \n",
       "\n",
       "                                                model4  model4_score  ...  \\\n",
       "0    Polizei verhaftet 15 nach gewaltttigem Protes...     14.448815  ...   \n",
       "1    Der Vorfall kommt nach einer Zunahme der Zahl ...     25.154173  ...   \n",
       "2    Das Innenministerium nutzt das Hotel seit letz...     40.719846  ...   \n",
       "3    Mehr als 45.000 Menschen erreichten Grobritan...     42.405909  ...   \n",
       "4    President's Cup: Candystripes besiegen Rovers ...     58.143074  ...   \n",
       "..                                                 ...           ...  ...   \n",
       "552  Ergonomisch und erschwinglich, aber nicht sehr...     17.542198  ...   \n",
       "553  Es hat eine schlankere Designform, die besser ...     31.718754  ...   \n",
       "554                     Du bekommst, wofr du bezahlst     16.233396  ...   \n",
       "555  Ich war enttuscht, als ich diesen Artikel erh...     25.972745  ...   \n",
       "556  Nichts wie die vorherigen Stylo-Telefone, MASS...     32.094305  ...   \n",
       "\n",
       "                                                model8  model8_score  \\\n",
       "0    Polizei verhaftet 15 Personen nach gewaltttig...     14.530346   \n",
       "1    Der Vorfall ereignete sich, nachdem die Zahl d...     34.150705   \n",
       "2    Lokalen Medien zufolge nutzt das Innenminister...     39.641643   \n",
       "3    Im Jahr 2022 erreichten mehr als 45.000 Mensch...     34.104278   \n",
       "4    President's Cup: Candystripes besiegen Rovers ...     58.143074   \n",
       "..                                                 ...           ...   \n",
       "552  Ergonomisch und erschwinglich, aber nicht sehr...     17.542198   \n",
       "553  Das schlankere Design liegt besser in der Hand...     28.587270   \n",
       "554                   Sie bekommen, wofr Sie bezahlen     16.233396   \n",
       "555  Ich war enttuscht, als ich diesen Artikel erh...     28.188503   \n",
       "556  Nichts wie die vorherigen Stylo-Telefone, RIES...     29.319509   \n",
       "\n",
       "                                                model9  model9_score  \\\n",
       "0    Polizeiverhaftung 15 nach gewaltsamen Protest...      4.495987   \n",
       "1    Die Polizei sagte, dass ein Polizist und zwei ...     14.294320   \n",
       "2    Das Home Office nutzt das Hotel seit letztem J...     42.385532   \n",
       "3    Das System zur Prfung von Asylantrgen hat si...     26.445337   \n",
       "4    President's Cup: Candystripes besiegen Rovers ...     57.212484   \n",
       "..                                                 ...           ...   \n",
       "552  Ergonomisch und erschwinglich, aber nicht sehr...     18.360281   \n",
       "553  Es hat eine schlankere Konstruktionsform, die ...     24.698036   \n",
       "554                       Du bekommst, wofr du zahlst     16.233396   \n",
       "555  Ich war enttuscht darber, dass der silberne ...     20.855679   \n",
       "556  Nichts wie die vorherigen Stylo Telefone, MASS...      4.528188   \n",
       "\n",
       "                                               model10  model10_score  \\\n",
       "0    Polizei nimmt 15 nach gewaltttigen Protesten ...      23.801761   \n",
       "1    Der Vorfall ereignete sich, nachdem die Zahl d...      28.939657   \n",
       "2    Das Innenministerium nutzt das Hotel seit letz...      36.082066   \n",
       "3    Mehr als 45.000 Menschen erreichten das Verein...      26.969867   \n",
       "4    President's Cup: Candystripes besiegen Rovers ...      58.143074   \n",
       "..                                                 ...            ...   \n",
       "552  Ergonomisch und erschwinglich, aber nicht sehr...      17.542198   \n",
       "553  Es hat eine schlankere Designform, die besser ...      30.391731   \n",
       "554                     Du bekommst, wofr du bezahlst      16.233396   \n",
       "555  Ich war enttuscht, als ich diesen Artikel erh...      25.673215   \n",
       "556  Nichts wie die vorherigen Stylo-Telefone, MASS...      26.854133   \n",
       "\n",
       "                                               model11  model11_score  \\\n",
       "0    Polizei nimmt 15 Personen nach gewaltsamen Pro...       8.516593   \n",
       "1    Der Vorfall ereignete sich, nachdem die Zahl d...      30.218550   \n",
       "2    Lokalen Medien zufolge nutzt das Innenminister...      29.267528   \n",
       "3    Im Jahr 2022 erreichten mehr als 45.000 Mensch...      37.961820   \n",
       "4    President's Cup: Candystripes besiegen Rovers ...      58.143074   \n",
       "..                                                 ...            ...   \n",
       "552  Ergonomisch und erschwinglich, aber nicht sehr...      17.542198   \n",
       "553  Er hat eine schlankere Form, die besser in der...      38.505105   \n",
       "554                   Sie bekommen, wofr Sie bezahlen      16.233396   \n",
       "555  Ich war enttuscht, als ich diesen Artikel erh...      30.392323   \n",
       "556  Nicht wie die vorherigen Stylo-Handys, MASSIVE...      35.127483   \n",
       "\n",
       "                                               model12  model12_score  \n",
       "0    Polizei verhaftet 15 nach gewaltttigem Protes...      14.448815  \n",
       "1    Der Vorfall ereignete sich nach einem Anstieg ...      27.196164  \n",
       "2    Lokalen Medien zufolge nutzt das Innenminister...      34.067354  \n",
       "3    ber 45.000 Menschen erreichten das Vereinigte...      33.754834  \n",
       "4    President's Cup: Candystripes besiegen Rovers ...      58.143074  \n",
       "..                                                 ...            ...  \n",
       "552  Ergonomisch und erschwinglich, aber wenig tole...      10.738977  \n",
       "553  Er hat ein schlankeres Design, das besser in d...      25.012669  \n",
       "554                     Sie bekommen, wofr Sie zahlen      16.233396  \n",
       "555  Ich war enttuscht, als ich diesen Artikel erh...      25.508720  \n",
       "556  Nichts wie die vorherigen Stylo-Handys, MASSIV...      25.613711  \n",
       "\n",
       "[557 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08d02a-b0f4-4011-ad8f-b858f181dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ddd5639-9c7c-4744-9366-0adb967be351",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b154095796c34716bfc06bc034f27abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53780c9bf6794b728ab8c528ef92615f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.0549\n",
      "Mean EMD on non-weighted test data: 0.0022\n",
      "Mean ED on non-weighted test data: 0.0106\n",
      "\n",
      "Mean k2 on weighted test data: 0.0486\n",
      "Mean EMD on weighted test data: 0.0018\n",
      "Mean ED on weighted test data: 0.0087\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e7fea44a95459db659a14efe6396df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.041\n",
      "Mean EMD on non-weighted test data: 0.0015\n",
      "Mean ED on non-weighted test data: 0.007\n",
      "\n",
      "Mean k2 on weighted test data: 0.0387\n",
      "Mean EMD on weighted test data: 0.0014\n",
      "Mean ED on weighted test data: 0.0064\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e265173fb14b1894159080838c494b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean k2 on non-weighted test data: 0.0553\n",
      "Mean EMD on non-weighted test data: 0.0021\n",
      "Mean ED on non-weighted test data: 0.0103\n",
      "\n",
      "Mean k2 on weighted test data: 0.0489\n",
      "Mean EMD on weighted test data: 0.0018\n",
      "Mean ED on weighted test data: 0.0086\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m grid_values \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m100\u001b[39m], \n\u001b[1;32m      8\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.009\u001b[39m],\n\u001b[1;32m      9\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m     10\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m]}\n\u001b[1;32m     12\u001b[0m pr \u001b[38;5;241m=\u001b[39m PropensityReweighter(config)\n\u001b[0;32m---> 13\u001b[0m best_predictor \u001b[38;5;241m=\u001b[39m \u001b[43mpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_gridsearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m best_weights \u001b[38;5;241m=\u001b[39m best_predictor\u001b[38;5;241m.\u001b[39mpredict(original)\n\u001b[1;32m     17\u001b[0m f1_all \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/workspace/local/edl/llm_propensity/propensity_reweighting/src/reweight.py:135\u001b[0m, in \u001b[0;36mPropensityReweighter.fit_gridsearch\u001b[0;34m(self, original, target, grid_params, parallel)\u001b[0m\n\u001b[1;32m    132\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    134\u001b[0m vctr_original \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess\u001b[38;5;241m.\u001b[39mvectorize_texts(original)\n\u001b[0;32m--> 135\u001b[0m vctr_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorize_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parallel \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    138\u001b[0m     parallel_units \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mcpu_count()\n",
      "File \u001b[0;32m/workspace/local/edl/llm_propensity/propensity_reweighting/src/preprocessing.py:26\u001b[0m, in \u001b[0;36mProScoreVectorizer.vectorize_texts\u001b[0;34m(self, texts_list)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, sent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(texts_list):\n\u001b[1;32m     19\u001b[0m     tokenized_sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode_plus(sent, \n\u001b[1;32m     20\u001b[0m                                        add_special_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     21\u001b[0m                                        truncation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,  \n\u001b[1;32m     22\u001b[0m                                        return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     23\u001b[0m                                        return_token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     24\u001b[0m                                        return_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     _cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_sent\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state[:,\u001b[38;5;241m0\u001b[39m,:]\n\u001b[1;32m     27\u001b[0m     cls_matrix[j, :] \u001b[38;5;241m=\u001b[39m _cls\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cls_matrix\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:837\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    828\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    830\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    831\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    832\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    835\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    836\u001b[0m )\n\u001b[0;32m--> 837\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    850\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:525\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    514\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    515\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    516\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m         output_attentions,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:456\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    453\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    454\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 456\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:468\u001b[0m, in \u001b[0;36mXLMRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 468\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:366\u001b[0m, in \u001b[0;36mXLMRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 366\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for item in tqdm(['model2', 'model3', 'model4','model5','model6']):\n",
    "    original = data[item].tolist()\n",
    "    labels = data[f\"{item}_score\"].tolist()\n",
    "\n",
    "    target = data[\"human_translate\"].tolist()\n",
    "\n",
    "    grid_values = {'n_estimators': [30, 100], \n",
    "               'learning_rate':[0.01, 0.001, 0.009],\n",
    "               'max_depth': [5, 10],\n",
    "               'min_samples_leaf': [1, 10, 100]}\n",
    "\n",
    "    pr = PropensityReweighter(config)\n",
    "    best_predictor = pr.fit_gridsearch(original, target, grid_values)\n",
    "\n",
    "    best_weights = best_predictor.predict(original)\n",
    "\n",
    "    f1_all = []\n",
    "    f1_all.append(f\"{len(target)}\")\n",
    "\n",
    "    f1 = round(np.average(data[f\"{item}_score\"]), 3), round(np.average(data[f\"{item}_score\"], weights=best_weights), 3)\n",
    "    f1_all.append(f\"{f1[0]} / {f1[1]}\")\n",
    "    \n",
    "    results[item] = f1_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9992c369-9261-4fc2-8547-64e9d0ee58e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['557', '38.592 / 39.44']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_all #model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84a068f0-60e3-4ada-bdae-fb6506242a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model2': ['557', '42.567 / 43.541'],\n",
       " 'model3': ['557', '43.065 / 43.359'],\n",
       " 'model4': ['557', '38.592 / 39.44']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75999a5f-1da2-4c64-a6bf-403de93f39d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
